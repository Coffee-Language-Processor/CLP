{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ujson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'data.json' ## insert filename here\n",
    "with open(filename) as f:\n",
    "    data = ujson.load(f)\n",
    "\n",
    "TRAINING_DATA = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in data:\n",
    "    tuple_1 = d['data']['response']\n",
    "    tuple_2 = {}\n",
    "    entities = []\n",
    "    results = d['annotations'][0]['result']\n",
    "    for x in results:\n",
    "        entities.append((x['value']['start'],  x['value']['end'], x['value']['labels'][0]))\n",
    "    tuple_2['entities'] = entities\n",
    "    TRAINING_DATA.append((tuple_1, tuple_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "from spacy.tokens import DocBin\n",
    "import spacy\n",
    "db = DocBin()\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "bad = 0\n",
    "\n",
    "for text, annotations in TRAINING_DATA:\n",
    "    doc = nlp(text)\n",
    "    ents = []\n",
    "    for start, end, label in annotations['entities']:\n",
    "        # print(text, text[start:end], label)\n",
    "        span = doc.char_span(start, end, label=label)\n",
    "        ents.append(span)\n",
    "    try:\n",
    "        doc.ents = ents\n",
    "        db.add(doc)\n",
    "    except:\n",
    "        bad += 1\n",
    "db.to_disk(\"./train.spacy\")\n",
    "print(bad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Saving to output directory: output_folder\u001b[0m\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[2022-12-01 00:00:30,489] [INFO] Set up nlp object from config\n",
      "[2022-12-01 00:00:30,506] [INFO] Pipeline: ['tok2vec', 'ner']\n",
      "[2022-12-01 00:00:30,512] [INFO] Created vocabulary\n",
      "[2022-12-01 00:00:30,514] [INFO] Finished initializing nlp object\n",
      "[2022-12-01 00:00:30,765] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     69.37   18.15   14.17   25.24    0.18\n",
      " 15     200        245.27   5570.43   99.23   99.16   99.30    0.99\n",
      " 35     400        191.20    458.68   99.72   99.58   99.86    1.00\n",
      " 59     600        150.94    180.51   99.86   99.86   99.86    1.00\n",
      " 88     800        137.90    124.53   99.86   99.86   99.86    1.00\n",
      "124    1000        167.05    119.65   99.86   99.86   99.86    1.00\n",
      "167    1200        120.93    103.75   99.86   99.86   99.86    1.00\n",
      "217    1400        276.58    152.44   99.86   99.86   99.86    1.00\n",
      "282    1600        247.64    170.40   99.86   99.86   99.86    1.00\n",
      "352    1800        124.96    117.82   99.86   99.86   99.86    1.00\n",
      "452    2000        189.91    187.71   99.86   99.86   99.86    1.00\n",
      "552    2200        165.75    175.95   99.86   99.86   99.86    1.00\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "output_folder/model-last\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train config.cfg --paths.train train.spacy --paths.dev train.spacy --output output_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Building package artifacts: wheel\u001b[0m\n",
      "\n",
      "\u001b[38;5;1m✘ Can't load pipeline meta.json\u001b[0m\n",
      "/Users/chris/Documents/UR/SENIOR/CSC412/Projects/Final/CLP/output_folder/model-best/meta.json\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy package \"/Users/chris/Documents/UR/SENIOR/CSC412/Projects/Final/CLP/output_folder/model-best\" \"/Users/chris/Documents/UR/SENIOR/CSC412/Projects/Final/CLP/CoffeeModel\" --build wheel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[38;5;1m✘ Not a valid .whl file:\n",
      "/Users/chris/Documents/UR/SENIOR/CSC412/Projects/Final/CLP/CoffeeModel/en_Coff_Ev1-1.0.4.\n",
      "Make sure to run `spacy package` with `--build wheel` to generate a wheel for\n",
      "you pipeline.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 1\n"
     ]
    }
   ],
   "source": [
    "from spacy_huggingface_hub import push\n",
    "\n",
    "result = push(\"/Users/chris/Documents/UR/SENIOR/CSC412/Projects/Final/CLP/CoffeeModel/en_Coff_Ev1-1.0.4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('data_mining')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2298ba359fbae6d6158f8907234987863a11850c54e05a14a74225930b181c78"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
